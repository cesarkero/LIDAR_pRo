enframe() %>%
unnest_tokens(ngrams, value, "ngrams", n = 2)
stopwords <- c("is", "the", "that", "to")
stopwords_collapsed <- paste(stopwords, collapse = "|")
#benchmark
txtexp <- rep(txt,100000)
dfexp <- txtexp %>%
enframe() %>%
unnest_tokens(ngrams, value, "ngrams", n = 2)
txt <- "Groundwater remediation is the process that is used to treat polluted groundwater by removing the pollutants or converting them into harmless products."
df <- txt %>%
enframe() %>%
unnest_tokens(ngrams, value, "ngrams", n = 2)
stopwords <- c("is", "the", "that", "to")
stopwords_collapsed <- paste(stopwords, collapse = "|")
#ANSWER 1
df1 %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)
#ANSWER 2
stopwords_collapsed <- paste(stopwords, collapse = "|")
df2 <- df[str_detect(df$ngrams, stopwords_collapsed) == FALSE, ]
#benchmark
txtexp <- rep(txt,100000)
dfexp <- txtexp %>%
enframe() %>%
unnest_tokens(ngrams, value, "ngrams", n = 2)
benchmark("dplyr function with txt" = {df1 <- df %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)},
"base selection with txt" = {df2 <- df[str_detect(df$ngrams, stopwords_collapsed) == FALSE, ]},
"dplyr function with txtexp (large text)" = {df3 <- dfexp %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)},
"base selection with txtextp (large text)" = {df4 <- dfexp[str_detect(dfexp$ngrams, stopwords_collapsed) == FALSE, ]}
replications = 10,
columns = c("test", "replications", "elapsed")
)
#benchmark
txtexp <- rep(txt,100000)
dfexp <- txtexp %>%
enframe() %>%
unnest_tokens(ngrams, value, "ngrams", n = 2)
benchmark("dplyr function with txt" = {df1 <- df %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)},
"base selection with txt" = {df2 <- df[str_detect(df$ngrams, stopwords_collapsed) == FALSE, ]},
"dplyr function with txtexp (large text)" = {df3 <- dfexp %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)},
"base selection with txtextp (large text)" = {df4 <- dfexp[str_detect(dfexp$ngrams, stopwords_collapsed) == FALSE, ]},
replications = 10,
columns = c("test", "replications", "elapsed")
)
benchmark("dplyr function with txt" = {df1 <- df %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)},
"base selection with txt" = {df2 <- df[str_detect(df$ngrams, stopwords_collapsed) == FALSE, ]},
"dplyr function with txtexp (large text)" = {df3 <- dfexp %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)},
"base selection with txtextp (large text)" = {df4 <- dfexp[str_detect(dfexp$ngrams, stopwords_collapsed) == FALSE, ]},
replications = 5,
columns = c("test", "replications", "elapsed")
)
#benchmark
txtexp <- rep(txt,1000000)
dfexp <- txtexp %>%
enframe() %>%
unnest_tokens(ngrams, value, "ngrams", n = 2)
benchmark("dplyr function with txt" = {df1 <- df %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)},
"base selection with txt" = {df2 <- df[str_detect(df$ngrams, stopwords_collapsed) == FALSE, ]},
"dplyr function with txtexp (large text)" = {df3 <- dfexp %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)},
"base selection with txtextp (large text)" = {df4 <- dfexp[str_detect(dfexp$ngrams, stopwords_collapsed) == FALSE, ]},
replications = 5,
columns = c("test", "replications", "elapsed")
)
benchmark("mutate+filter (small text)" = {df1 <- df %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)},
"[] row selection (small text)" = {df2 <- df[str_detect(df$ngrams, stopwords_collapsed) == FALSE, ]},
"mutate+filter (large text)" = {df3 <- dfexp %>%
mutate(
has_stop_word = str_detect(ngrams, stopwords_collapsed)
) %>%
filter(!has_stop_word)},
"[] row selection (large text)" = {df4 <- dfexp[str_detect(dfexp$ngrams, stopwords_collapsed) == FALSE, ]},
replications = 5,
columns = c("test", "replications", "elapsed")
)
df
df2
install.packages("jsonlite")
libraries("jsonlite")
library(jsonlite)
json_file <- "http://servizos.meteogalicia.gal/rss/observacion/listaEstacionsMeteo.action"
json_file <- "http://servizos.meteogalicia.gal/rss/observacion/listaEstacionsMeteo.action"
data <- fromJSON(json_file)
write.csv(data, "data.csv")
getwd(9)
getwd()
library(raster)
library(rgdal)
library(gdalUtils)
library(rgeos)
library(readr)
library(dismo)
library(rJava)
# Si java no funciona ejecutar la siguiente linea con la ruta de instalacion
# Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_211')
library(ggplot2)
library(parallel)
library(foreach)
library(doParallel)
library(sf)
# PARAMETROS
RastersAscDir <- "./_Asc/"
OccurrentesCsv <- "./_Asc/Edificios.csv"
outputmax <- "./output_maxent/"
outputbio <- "./output_bioclim/"
epsg <- crs('+init=epsg:25829')
lightdir <- "./_Asc_light/"
shp <- "Z:/Material/SIG/_01_Limites/_06_CA/Comunidade_Autonoma_IGN.shp"
shpdir <- "Z:/Material/SIG/_01_Limites/_06_CA/Comunidade_Autonoma_IGN.shp"
shp <- readOGR(dsn = shpdir, layer = shpdir)
library(sp)
shpdir <- "Z:/Material/SIG/_01_Limites/_06_CA/Comunidade_Autonoma_IGN.shp"
shp <- readOGR(dsn = shpdir, layer = shpdir)
library(sf)
shp <- readOGR(dsn = shpdir, layer = shpdir)
library(raster)
shpdir <- "Z:/Material/SIG/_01_Limites/_06_CA/Comunidade_Autonoma_IGN.shp"
shp <- readOGR(dsn = shpdir, layer = shpdir)
library(rgdal)
shpdir <- "Z:/Material/SIG/_01_Limites/_06_CA/Comunidade_Autonoma_IGN.shp"
shp <- readOGR(dsn = shpdir, layer = shpdir)
shp <- readOGR(dsn = shpdir, layer = "Comunidade_Autonoma_IGN.shp")
shpdir <- "Z:/Material/SIG/_01_Limites/_06_CA/"
shp <- readOGR(dsn = shpdir, layer = "Comunidade_Autonoma_IGN.shp")
library(rgdal)
shpdir <- "Z:/Material/SIG/_01_Limites/_06_CA/"
shp <- readOGR(dsn = shpdir, layer = "Comunidade_Autonoma_IGN")
shpdir <- "Z:/Material/SIG/_01_Limites/_06_CA"
shp <- readOGR(dsn = shpdir, layer = "Comunidade_Autonoma_IGN")
shp <- readOGR(dsn = shpdir, layer = "Comunidade_Autonoma_IGN")
shp_buf <- gBuffer(shp, width = 25)
library(rgeos)
shp_buf <- gBuffer(shp, width = 25)
plot(shp_buf)
plot(shp)
plot(shp_buf, add=TRUE)
library(rgdal)
library(rgeos)
shpdir <- "Z:/Material/SIG/_01_Limites/_06_CA"
shp <- readOGR(dsn = shpdir, layer = "Comunidade_Autonoma_IGN")
shp_buf <- gBuffer(shp, width = 25000)
plot(shp)
plot(shp_buf, add=TRUE)
library(raster)
library(rgdal)
r <- choose.files()
r
?rasterToPoints
basename((r))
baseenv()
baseenv(r)
dirname(r)
os.path.split(r)
file.path(r)
split_path <- function(x) if (dirname(x)==x) x else c(basename(x),split_path(dirname(x)))
split_path(r)
file.path(r)
split_path(r)
split_path <- function(path) {rev(setdiff(strsplit(path,"/|\\\\")[[1]], ""))}
split_path(r)
file.path(r)
splot_path[-1]
split_path[-1]
split_path[2,]
split_path(r)[2,]
split_path(r)[-1]
paste(split_path(r)[-1], sep='/')
paste(split_path(r)[-1], sep='/')
paste(split_path(r)[-1], sep='/', collapse = TRUE)
paste(split_path(r)[-1], sep='/', collapse)
paste(split_path(r)[-1], sep='/', collapse = 1)
paste(split_path(r)[-1], collapse = "/")
paste(rev(split_path(r)[-1]), collapse = "/")
paste(rev(split_path(r)[-1]),"/", collapse = "/")
paste(rev(split_path(r)[-1]), collapse = "/")
#save file in the same folder adding something at the filename
split_path <- function(path) {setdiff(strsplit(path,"/|\\\\")[[1]], "")}
paste(rev(split_path(r)[-1]), collapse = "/")
split_path(r)
split_path(r)[,-1]
#Get the folder name of a file
split_path <- function(path) {setdiff(strsplit(path,"/|\\\\")[[1]], "")}
split_path(r)
split_path(r)[-length(split_path(r))]
paste(rev(split_path(r)[1]), collapse = "/")
paste(split_path(r)[-length(split_path(r))], collapse = "/")
#Get the folder name of a file
folderpath <- function(path) {
x <- setdiff(strsplit(path,"/|\\\\")[[1]], "")
paste(x[-length(x)], collapse = "/")
}
folderpath(r)
basename(r)
basename(r)
library(raster)
library(rgdal)
r <- choose.files() #choose raster file
#Get the folderpath of a filepath
folderpath <- function(path) {
x <- setdiff(strsplit(path,"/|\\\\")[[1]], "")
paste(x[-length(x)], collapse = "/")
}
rp <- rasterToPoints(r, spatial = TRUE) # Add filter function fun=function(x){x>3)}
rp <- rasterToPoints(r, spatial = TRUE)
library(raster)
library(rgdal)
r <- raster(choose.files()) #choose raster file
#Get the folderpath of a filepath
folderpath <- function(path) {
x <- setdiff(strsplit(path,"/|\\\\")[[1]], "")
paste(x[-length(x)], collapse = "/")
}
rp <- rasterToPoints(r, spatial = TRUE) # Add filter function fun=function(x){x>3)}
#ver droplets existentes
droplets()
library(analogsea)
install.packages("analogsea")
#ver droplets existentes
droplets()
library(analogsea)
droplets()
#ver droplets existentes
droplets()
??analogsea
droplets() #ver droplets existentes
droplet_power_on(droplets()$vm00) #encender
Raster <- "C:/Users/cac/Desktop/Fernandina/MDT25/MDT25.tif" #uncoment this to use the code out of qgis
#Get the folderpath of a filepath
folderpath <- function(path) {
x <- setdiff(strsplit(path,"/|\\\\")[[1]], "")
paste(x[-length(x)], collapse = "/")
}
r <- raster(Raster) #r is the object of class 'raster'.
basename(Raster)
?basename
folderpath(Raster)
#Get the folderpath of a filepath
folderpath <- function(path) {
x <- setdiff(strsplit(path,"/|\\\\")[[1]], "")
paste0(paste(x[-length(x)], collapse = "/"),"/")
}
folderpath(Raster)
gsub('.{4}$', '', basename(Raster))
gsub('.{4}$', '', basename(Raster))
folderpath(Raster)
library(raster)
Raster <- "C:/Users/cac/Desktop/Fernandina/MDT25/MDT25.tif" #uncoment this to use the code out of qgis
#Get the folderpath of a filepath
folderpath <- function(path) {
x <- setdiff(strsplit(path,"/|\\\\")[[1]], "")
paste0(paste(x[-length(x)], collapse = "/"),"/")
}
gsub('.{3}$', '', cs)
gsub(pattern = "\\.$", "", Raster)
r <- raster(Raster) #r is the object of class 'raster'.
r[is.na(r[])] <- 0 # replacing NA's by zero
rname <- paste0(folderpath(Raster),
gsub('.{4}$', '', basename(Raster)),
"_mar0.tif")
writeRaster(r, rname)
rname
library(raster)
Raster <- "C:/Users/cac/Desktop/Fernandina/MDT25/MDT25.tif" #uncoment this to use the code out of qgis
#Get the folderpath of a filepath
folderpath <- function(path) {
x <- setdiff(strsplit(path,"/|\\\\")[[1]], "")
paste0(paste(x[-length(x)], collapse = "/"),"/")
}
r <- raster(Raster) #r is the object of class 'raster'.
plot(r)
r[is.na(r[])] <- 0 # replacing NA's by zero
plot(r)
rname <- paste0(folderpath(Raster),
gsub('.{4}$', '', basename(Raster)),
"_mar0.tif")
?writeRaster
writeRaster(r, rname, format="GTiff", overwrite=TRUE)
library(stringr)
list <- c(1,2,3,6,7,8,9,10,20,21,22,23,24,25,43,44,45,46,47,48,49,50,67,68,69,70,
71,72,73,74,75,92,93,94,95,96,97,98,99,100,119,120,121,122,123,124,125,
126,151,152,153,154,155,156,157,184,185,186,187,188,189,190,191,222,223,
224,225,226,227,228,229,260,261,262,263,264,265,266,298,299,300,301,302,
303,304,298,299,300,301,302,303,304,336,'302B','303B')
path <- "D:/_10_LIDAR_CNIG/2015/"
FolderPillars <- function (l, p, mainfoldername, padnum = 4, padchar = "0",
subfolders = c("CNIG_descarga"), subsubfolders = c("")){
for (i in l){
#create folder name
name <- paste0(p, mainfoldername, str_pad(i, padnum, "left", pad = padchar), "/")
#if doesn't exist create and add a new folder structure inside
if (!dir.exists(name)){
dir.create(name)
for (sf in subfolders){
dir.create(paste0(name,sf,"/"))
for (ssf in subsubfolders){
dir.create(paste0(paste0(name,sf,"/"),sf,"/"))
}
}
} else {
print("Dir already exists!")
}
}
}
FolderPillars(list, path, "MTN")
library(stringr)
list <- c(1,2,3,6,7,8,9,10,20,21,22,23,24,25,43,44,45,46,47,48,49,50,67,68,69,70,
71,72,73,74,75,92,93,94,95,96,97,98,99,100,119,120,121,122,123,124,125,
126,151,152,153,154,155,156,157,184,185,186,187,188,189,190,191,222,223,
224,225,226,227,228,229,260,261,262,263,264,265,266,298,299,300,301,302,
303,304,298,299,300,301,302,303,304,336,'302B','303B')
path <- "D:/_10_LIDAR_CNIG/2015/"
FolderPillars <- function (l, p, mainfoldername, padnum = 4, padchar = "0",
subfolders = c("CNIG_descarga"), subsubfolders = c("")){
for (i in l){
#create folder name
name <- paste0(p, mainfoldername, str_pad(i, padnum, "left", pad = padchar), "/")
#if doesn't exist create and add a new folder structure inside
if (!dir.exists(name)){
dir.create(name)
for (sf in subfolders){
dir.create(paste0(name,sf,"/"))
for (ssf in subsubfolders){
dir.create(paste0(name,sf,"/"),ssf,"/")
}
}
} else {
print("Dir already exists!")
}
}
}
FolderPillars(list, path, "MTN")
install.packages("RSelenium")
library(RSelenium)
startServer()
mybrowser$open()
mybrowser <- remoteDriver()
mybrowser$open()
mybrowser$navigate("http://centrodedescargas.cnig.es/CentroDescargas/index.jsp#")
mybrowser$navigate("http://centrodedescargas.cnig.es/CentroDescargas/index.jsp")
mybrowser$navigate("http://centrodedescargas.cnig.es/CentroDescargas/")
mybrowser$navigate("http://centrodedescargas.cnig.es")
rD=rsDriver()
mybrowser <- remoteDriver(remoteServerAddr = "localhost", port = 4445L, browserName = "firefox")
mybrowser$open()
mybrowser <- remoteDriver(remoteServerAddr = "localhost", port = 4445, browserName = "firefox")
mybrowser$open()
setwd("C:/Users/cac/GoogleDrive/GitHub/LIDAR_pRo")
source("00_Base.R")
# lasdir <- choose_folder(caption = "Select las dir:") #select dir to las or laz
# output <- choose_folder(caption = "Select output dir:") #output dir
lasdir <- "Z:/Proxectos/d002_Mirador_Fernandina/LIDAR_CNIG/"
output <- "Z:/Proxectos/d002_Mirador_Fernandina/LIDAR_products/"
clipcatshape = readOGR("Z:/Proxectos/d002_Mirador_Fernandina/AltoDaFernandina.gpkg", "Buffer_1000m")
epsg = "+init=epsg:25829"
res = 0.5
pattern = '*COL.laz$ || *COL.LAZ$'
clipcat = TRUE
clipcatbuf = FALSE
clipbuf = 1000
clipcatshape
cat <- catalog(list.files(path = lasdir, recursive = TRUE, pattern = pattern, full.names = TRUE))
projection(cat) <- epsg
opt_progress(cat) <- progress #see progress
opt_laz_compression(cat) <- laz_compression #laz compression
progress = TRUE
cat_chunk_buffer = 20
cores = 4
laz_compression = TRUE
epsg = "+init=epsg:25829"
projection(cat) <- epsg
opt_progress(cat) <- progress #see progress
opt_laz_compression(cat) <- laz_compression #laz compression
if (clipcat == TRUE) {
opt_output_files(cat) <- paste0(output, "Catalog_clip")
if (clipcatbuf == TRUE) {
cat_clip = lasclip(cat, buffer(clipcatshape, width=1000)) #clip from buffer
} else {
cat_clip = lasclip(cat, clipshape)
}
}
if (clipcat == TRUE) {
opt_output_files(cat) <- paste0(output, "Catalog_clip")
if (clipcatbuf == TRUE) {
cat_clip = lasclip(cat, buffer(clipcatshape, width=1000)) #clip from buffer
} else {
cat_clip = lasclip(cat, clipcatshape)
}
}
cat_clip
cat_clip
cat <- cat_clip
cat
opt_cores(cat) <- cores #change cores option
cat
retilecatalog = FALSE
if (retilecatalog == FALSE){
opt_chunk_buffer(cat) <- cat_chunk_buffer #change buffer size
writeOGR(as.spatial(cat), paste0(outputdir,"Catalog.gpkg"),"catalog", driver="GPKG") #geopackage
return(cat)
} else {
#crear nueva carpeta de retile en output
name <- paste0(output, basename(lasdir),"_retile_", toString(tile_chunk_size), "/")
dir.create(name)
cat <- catalog(list.files(path = lasdir, pattern = pattern, full.names = TRUE, recursive = TRUE))
projection(cat) <- epsg
opt_output_files(cat) <- paste0(name, basename(lasdir), "_","{XLEFT}","_","{YTOP}")
opt_chunk_buffer(cat) <- tile_chunk_buffer
opt_chunk_size(cat) <- tile_chunk_size
if (filterask == TRUE){
opt_filter(cat) <- filter
}
opt_laz_compression(cat) <- laz_compression #laz compression
newcat <- catalog_retile(cat)
writeOGR(as.spatial(newcat), paste0(name,"catalog.gpkg"),"catalog", driver="GPKG") #geopackage
return(newcat)
}
outputdir = output
if (retilecatalog == FALSE){
opt_chunk_buffer(cat) <- cat_chunk_buffer #change buffer size
writeOGR(as.spatial(cat), paste0(outputdir,"Catalog.gpkg"),"catalog", driver="GPKG") #geopackage
return(cat)
} else {
#crear nueva carpeta de retile en output
name <- paste0(output, basename(lasdir),"_retile_", toString(tile_chunk_size), "/")
dir.create(name)
cat <- catalog(list.files(path = lasdir, pattern = pattern, full.names = TRUE, recursive = TRUE))
projection(cat) <- epsg
opt_output_files(cat) <- paste0(name, basename(lasdir), "_","{XLEFT}","_","{YTOP}")
opt_chunk_buffer(cat) <- tile_chunk_buffer
opt_chunk_size(cat) <- tile_chunk_size
if (filterask == TRUE){
opt_filter(cat) <- filter
}
opt_laz_compression(cat) <- laz_compression #laz compression
newcat <- catalog_retile(cat)
writeOGR(as.spatial(newcat), paste0(name,"catalog.gpkg"),"catalog", driver="GPKG") #geopackage
return(newcat)
}
cat
res = 0.5
# MDT PROCESS (FUNCIONA)
MDT_output <- paste0(output,"MDT_", str_pad(res, 3, "left", pad = "0"), "/")
opt_output_files(cat) <- paste0(MDT_output,"{ORIGINALFILENAME}") #set filepaths
MDT <- grid_terrain(cat, res = res, algorithm = "knnidw"(k = 5, p = 2))
# plot(MDT)
# hillshade for MDT
MDT_hs = hs(MDT)
# plot(MDT_hs)
# export raster files
writeRaster(MDT_hs,
filename=paste(MDT_output,"/", "grid_terrain_hs.tif", sep=''),
datatype="FLT4S",
overwrite=T)
gc()
#-------------------------------------------------------------------------------
# MDS PROCESS (FUNCIONA)
MDS_output <- paste0(output,"MDS_", str_pad(res, 3, "left", pad = "0"), "/")
opt_output_files(cat) <- paste0(MDS_output,"{ORIGINALFILENAME}") #set filepaths
# Method 1: point to raster. ojo, crea vacios donde no hay vegetacion.
# MDS <- grid_canopy(cat, res = res, p2r())
# Method 2: Basic triangulation and rasterization of first returns
MDS <- grid_canopy(cat, res = res, dsmtin())
# Method 3: Khosravipour et al. pitfree algorithm
# MDS <- grid_canopy(cat, res = res, pitfree(c(0,2,5,10,15), c(0, 1.5)))
# hillshade for MDE
MDS_hs = hs(MDS)
# plot(MDS_hs)
# export raster files
writeRaster(MDS_hs,
filename=paste(MDS_output,"/", "MDS_hs.tif", sep=''),
datatype="FLT4S",
overwrite=T)
gc()
